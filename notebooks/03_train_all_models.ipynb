{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# AlexNet iFood2019 - Train All Models\n",
                "\n",
                "This notebook trains all 4 AlexNet variants sequentially:\n",
                "1. alexnet_baseline\n",
                "2. alexnet_mod1 (with BatchNorm)\n",
                "3. alexnet_mod2 (with Dropout)\n",
                "4. alexnet_combined (BatchNorm + Dropout + improvements)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# Cell 1: Setup\n",
                "# ============================================================\n",
                "\n",
                "from google.colab import drive\n",
                "drive.mount('/content/drive')\n",
                "\n",
                "import os\n",
                "import sys\n",
                "\n",
                "PROJECT_PATH = '/content/drive/MyDrive/AlexNet_iFood2019'\n",
                "REPO_PATH = '/content/alexnet-ifood2019'\n",
                "\n",
                "if not os.path.exists(REPO_PATH):\n",
                "    !git clone https://github.com/deftorch/alexnet-ifood2019.git {REPO_PATH}\n",
                "\n",
                "os.chdir(REPO_PATH)\n",
                "sys.path.insert(0, REPO_PATH)\n",
                "\n",
                "# Create symlinks\n",
                "!rm -rf data checkpoints evaluation_results analysis_results\n",
                "!ln -s {PROJECT_PATH}/dataset data\n",
                "!ln -s {PROJECT_PATH}/checkpoints checkpoints\n",
                "!ln -s {PROJECT_PATH}/evaluation_results evaluation_results\n",
                "!ln -s {PROJECT_PATH}/analysis_results analysis_results\n",
                "\n",
                "print(\"‚úì Setup complete\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# Cell 2: Install Dependencies\n",
                "# ============================================================\n",
                "\n",
                "!pip install -q torch torchvision pandas numpy pillow scikit-learn matplotlib seaborn tqdm wandb\n",
                "\n",
                "import torch\n",
                "print(f\"PyTorch: {torch.__version__}\")\n",
                "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
                "if torch.cuda.is_available():\n",
                "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# Cell 3: Training Configuration\n",
                "# ============================================================\n",
                "\n",
                "MODELS = [\n",
                "    'alexnet_baseline',\n",
                "    'alexnet_mod1',\n",
                "    'alexnet_mod2',\n",
                "    'alexnet_combined'\n",
                "]\n",
                "\n",
                "# Training settings\n",
                "NUM_EPOCHS = 50\n",
                "BATCH_SIZE = 128\n",
                "LR = 0.01\n",
                "USE_WANDB = False  # Set True for WandB logging\n",
                "\n",
                "print(\"Models to train:\")\n",
                "for i, m in enumerate(MODELS, 1):\n",
                "    print(f\"  {i}. {m}\")\n",
                "print(f\"\\nEpochs: {NUM_EPOCHS}, Batch Size: {BATCH_SIZE}, LR: {LR}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# Cell 4: Train All Models Sequentially\n",
                "# ============================================================\n",
                "\n",
                "import time\n",
                "\n",
                "training_times = {}\n",
                "\n",
                "for model_name in MODELS:\n",
                "    print(\"\\n\" + \"=\" * 70)\n",
                "    print(f\"TRAINING: {model_name}\")\n",
                "    print(\"=\" * 70)\n",
                "    \n",
                "    start_time = time.time()\n",
                "    \n",
                "    wandb_flag = \"--use_wandb\" if USE_WANDB else \"\"\n",
                "    \n",
                "    !python src/train.py \\\n",
                "        --data_dir data \\\n",
                "        --model_name {model_name} \\\n",
                "        --num_epochs {NUM_EPOCHS} \\\n",
                "        --batch_size {BATCH_SIZE} \\\n",
                "        --lr {LR} \\\n",
                "        --save_dir checkpoints \\\n",
                "        {wandb_flag}\n",
                "    \n",
                "    elapsed = time.time() - start_time\n",
                "    training_times[model_name] = elapsed\n",
                "    \n",
                "    print(f\"\\n‚úì Completed {model_name} in {elapsed/60:.1f} minutes\")\n",
                "\n",
                "print(\"\\n\" + \"=\" * 70)\n",
                "print(\"ALL MODELS TRAINED!\")\n",
                "print(\"=\" * 70)\n",
                "for model, t in training_times.items():\n",
                "    print(f\"  {model}: {t/60:.1f} min\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# Cell 5: Evaluate All Models\n",
                "# ============================================================\n",
                "\n",
                "print(\"\\nEvaluating all models...\\n\")\n",
                "\n",
                "for model_name in MODELS:\n",
                "    print(f\"Evaluating: {model_name}\")\n",
                "    \n",
                "    !python src/evaluate.py \\\n",
                "        --data_dir data \\\n",
                "        --model_path checkpoints/{model_name}_best.pth \\\n",
                "        --model_name {model_name} \\\n",
                "        --split val \\\n",
                "        --output_dir evaluation_results\n",
                "    \n",
                "    print(f\"‚úì Evaluated: {model_name}\\n\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# Cell 6: Run Comparative Analysis\n",
                "# ============================================================\n",
                "\n",
                "!python src/analysis.py \\\n",
                "    --checkpoint_dir checkpoints \\\n",
                "    --eval_dir evaluation_results \\\n",
                "    --output_dir analysis_results \\\n",
                "    --models alexnet_baseline alexnet_mod1 alexnet_mod2 alexnet_combined\n",
                "\n",
                "print(\"\\n‚úì Comparative analysis complete!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# Cell 7: Display Results Summary\n",
                "# ============================================================\n",
                "\n",
                "import json\n",
                "import pandas as pd\n",
                "\n",
                "results = []\n",
                "\n",
                "for model_name in MODELS:\n",
                "    row = {'Model': model_name}\n",
                "    \n",
                "    # Load history\n",
                "    history_file = f'checkpoints/{model_name}_history.json'\n",
                "    if os.path.exists(history_file):\n",
                "        with open(history_file) as f:\n",
                "            history = json.load(f)\n",
                "        row['Best Val Acc'] = max(history['val_acc'])\n",
                "        row['Best Epoch'] = history['val_acc'].index(max(history['val_acc'])) + 1\n",
                "    \n",
                "    # Load metrics\n",
                "    metrics_file = f'evaluation_results/{model_name}_val_metrics.json'\n",
                "    if os.path.exists(metrics_file):\n",
                "        with open(metrics_file) as f:\n",
                "            metrics = json.load(f)\n",
                "        row['Test Acc'] = metrics.get('accuracy', 0)\n",
                "        row['Top-5 Acc'] = metrics.get('top5_accuracy', 0)\n",
                "        row['Macro F1'] = metrics.get('macro_f1', 0)\n",
                "    \n",
                "    results.append(row)\n",
                "\n",
                "df = pd.DataFrame(results)\n",
                "\n",
                "print(\"\\n\" + \"=\" * 80)\n",
                "print(\"FINAL RESULTS\")\n",
                "print(\"=\" * 80)\n",
                "print(df.to_string(index=False))\n",
                "print(\"=\" * 80)\n",
                "\n",
                "# Find best model\n",
                "if 'Best Val Acc' in df.columns:\n",
                "    best_idx = df['Best Val Acc'].idxmax()\n",
                "    best_model = df.iloc[best_idx]['Model']\n",
                "    print(f\"\\nüèÜ Best Model: {best_model}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# Cell 8: Display Analysis Plots\n",
                "# ============================================================\n",
                "\n",
                "from IPython.display import Image, display\n",
                "import os\n",
                "\n",
                "plots = [\n",
                "    'training_curves_comparison.png',\n",
                "    'metrics_comparison.png',\n",
                "    'confusion_matrices.png'\n",
                "]\n",
                "\n",
                "for plot in plots:\n",
                "    path = f'analysis_results/{plot}'\n",
                "    if os.path.exists(path):\n",
                "        print(f\"\\n{plot}:\")\n",
                "        display(Image(filename=path, width=800))\n",
                "    else:\n",
                "        print(f\"‚ö†Ô∏è  Not found: {plot}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# Cell 9: Sync to Drive\n",
                "# ============================================================\n",
                "\n",
                "print(\"Syncing results to Google Drive...\")\n",
                "\n",
                "# Results are already synced via symlinks\n",
                "# But let's verify\n",
                "\n",
                "print(f\"\\nCheckpoints: {len(os.listdir('checkpoints'))} files\")\n",
                "print(f\"Evaluation results: {len(os.listdir('evaluation_results'))} files\")\n",
                "print(f\"Analysis results: {len(os.listdir('analysis_results'))} files\")\n",
                "\n",
                "print(f\"\\n‚úì All results saved to: {PROJECT_PATH}\")\n",
                "print(\"\\nüéâ Training pipeline complete!\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "accelerator": "GPU"
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
