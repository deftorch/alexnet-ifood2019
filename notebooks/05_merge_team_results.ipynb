{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üìä Merge Results - Gabungkan Hasil Semua Member\n",
                "\n",
                "Jalankan notebook ini **SETELAH** semua 4 member selesai training.\n",
                "\n",
                "Notebook ini akan:\n",
                "1. Mengumpulkan hasil dari semua model\n",
                "2. Membuat perbandingan\n",
                "3. Generate visualisasi\n",
                "4. Membuat summary untuk report\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# SETUP\n",
                "# ============================================================\n",
                "\n",
                "from google.colab import drive\n",
                "drive.mount('/content/drive')\n",
                "\n",
                "import os\n",
                "import sys\n",
                "import json\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "\n",
                "PROJECT_PATH = '/content/drive/MyDrive/AlexNet_iFood2019'\n",
                "CHECKPOINT_DIR = os.path.join(PROJECT_PATH, 'checkpoints')\n",
                "EVAL_DIR = os.path.join(PROJECT_PATH, 'evaluation_results')\n",
                "ANALYSIS_DIR = os.path.join(PROJECT_PATH, 'analysis_results')\n",
                "\n",
                "os.makedirs(ANALYSIS_DIR, exist_ok=True)\n",
                "\n",
                "MODELS = ['alexnet_baseline', 'alexnet_mod1', 'alexnet_mod2', 'alexnet_combined']\n",
                "MEMBER_NAMES = ['Member 1', 'Member 2', 'Member 3', 'Member 4']\n",
                "\n",
                "print(\"‚úÖ Setup complete\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# CEK KELENGKAPAN FILE\n",
                "# ============================================================\n",
                "\n",
                "print(\"üìÅ Checking files from all members...\\n\")\n",
                "\n",
                "all_complete = True\n",
                "\n",
                "for i, model in enumerate(MODELS):\n",
                "    history_file = os.path.join(CHECKPOINT_DIR, f'{model}_history.json')\n",
                "    metrics_file = os.path.join(EVAL_DIR, f'{model}_val_metrics.json')\n",
                "    \n",
                "    h_exists = os.path.exists(history_file)\n",
                "    m_exists = os.path.exists(metrics_file)\n",
                "    \n",
                "    status = \"‚úÖ\" if (h_exists and m_exists) else \"‚ùå\"\n",
                "    print(f\"{status} {MEMBER_NAMES[i]}: {model}\")\n",
                "    print(f\"   History: {'‚úì' if h_exists else '‚úó'}  Metrics: {'‚úì' if m_exists else '‚úó'}\")\n",
                "    \n",
                "    if not (h_exists and m_exists):\n",
                "        all_complete = False\n",
                "\n",
                "print()\n",
                "if all_complete:\n",
                "    print(\"üéâ Semua file lengkap! Lanjutkan ke cell berikutnya.\")\n",
                "else:\n",
                "    print(\"‚ö†Ô∏è  Ada file yang belum lengkap. Pastikan semua member sudah selesai training.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# LOAD SEMUA HASIL\n",
                "# ============================================================\n",
                "\n",
                "histories = {}\n",
                "metrics = {}\n",
                "\n",
                "for model in MODELS:\n",
                "    # Load history\n",
                "    history_file = os.path.join(CHECKPOINT_DIR, f'{model}_history.json')\n",
                "    if os.path.exists(history_file):\n",
                "        with open(history_file) as f:\n",
                "            histories[model] = json.load(f)\n",
                "    \n",
                "    # Load metrics\n",
                "    metrics_file = os.path.join(EVAL_DIR, f'{model}_val_metrics.json')\n",
                "    if os.path.exists(metrics_file):\n",
                "        with open(metrics_file) as f:\n",
                "            metrics[model] = json.load(f)\n",
                "\n",
                "print(f\"Loaded {len(histories)} histories, {len(metrics)} metrics\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# TABEL PERBANDINGAN\n",
                "# ============================================================\n",
                "\n",
                "results = []\n",
                "\n",
                "for i, model in enumerate(MODELS):\n",
                "    row = {\n",
                "        'Member': MEMBER_NAMES[i],\n",
                "        'Model': model.replace('alexnet_', '').upper()\n",
                "    }\n",
                "    \n",
                "    if model in histories:\n",
                "        h = histories[model]\n",
                "        row['Best Val Acc'] = max(h['val_acc'])\n",
                "        row['Best Epoch'] = h['val_acc'].index(max(h['val_acc'])) + 1\n",
                "    \n",
                "    if model in metrics:\n",
                "        m = metrics[model]\n",
                "        row['Test Acc'] = m.get('accuracy', 0)\n",
                "        row['Top-5 Acc'] = m.get('top5_accuracy', 0)\n",
                "        row['Macro F1'] = m.get('macro_f1', 0)\n",
                "    \n",
                "    results.append(row)\n",
                "\n",
                "df = pd.DataFrame(results)\n",
                "\n",
                "print(\"=\" * 80)\n",
                "print(\"üìä PERBANDINGAN HASIL SEMUA MEMBER\")\n",
                "print(\"=\" * 80)\n",
                "print(df.to_string(index=False))\n",
                "print(\"=\" * 80)\n",
                "\n",
                "# Best model\n",
                "if 'Best Val Acc' in df.columns:\n",
                "    best_idx = df['Best Val Acc'].idxmax()\n",
                "    print(f\"\\nüèÜ Model Terbaik: {df.iloc[best_idx]['Model']} ({df.iloc[best_idx]['Member']})\")\n",
                "    print(f\"   Accuracy: {df.iloc[best_idx]['Best Val Acc']:.4f}\")\n",
                "\n",
                "# Save\n",
                "df.to_csv(os.path.join(ANALYSIS_DIR, 'team_results_comparison.csv'), index=False)\n",
                "print(f\"\\n‚úÖ Saved to: {ANALYSIS_DIR}/team_results_comparison.csv\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# TRAINING CURVES COMPARISON\n",
                "# ============================================================\n",
                "\n",
                "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
                "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']\n",
                "\n",
                "# Loss curves\n",
                "ax = axes[0, 0]\n",
                "for (model, hist), color in zip(histories.items(), colors):\n",
                "    epochs = range(1, len(hist['train_loss']) + 1)\n",
                "    ax.plot(epochs, hist['train_loss'], color=color, label=model, linewidth=2)\n",
                "ax.set_xlabel('Epoch')\n",
                "ax.set_ylabel('Loss')\n",
                "ax.set_title('Training Loss')\n",
                "ax.legend()\n",
                "ax.grid(alpha=0.3)\n",
                "\n",
                "ax = axes[0, 1]\n",
                "for (model, hist), color in zip(histories.items(), colors):\n",
                "    epochs = range(1, len(hist['val_loss']) + 1)\n",
                "    ax.plot(epochs, hist['val_loss'], color=color, label=model, linewidth=2)\n",
                "ax.set_xlabel('Epoch')\n",
                "ax.set_ylabel('Loss')\n",
                "ax.set_title('Validation Loss')\n",
                "ax.legend()\n",
                "ax.grid(alpha=0.3)\n",
                "\n",
                "# Accuracy curves\n",
                "ax = axes[1, 0]\n",
                "for (model, hist), color in zip(histories.items(), colors):\n",
                "    epochs = range(1, len(hist['train_acc']) + 1)\n",
                "    ax.plot(epochs, hist['train_acc'], color=color, label=model, linewidth=2)\n",
                "ax.set_xlabel('Epoch')\n",
                "ax.set_ylabel('Accuracy')\n",
                "ax.set_title('Training Accuracy')\n",
                "ax.legend()\n",
                "ax.grid(alpha=0.3)\n",
                "\n",
                "ax = axes[1, 1]\n",
                "for (model, hist), color in zip(histories.items(), colors):\n",
                "    epochs = range(1, len(hist['val_acc']) + 1)\n",
                "    ax.plot(epochs, hist['val_acc'], color=color, label=model, linewidth=2)\n",
                "ax.set_xlabel('Epoch')\n",
                "ax.set_ylabel('Accuracy')\n",
                "ax.set_title('Validation Accuracy')\n",
                "ax.legend()\n",
                "ax.grid(alpha=0.3)\n",
                "\n",
                "plt.suptitle('Training Curves - All Models', fontsize=14)\n",
                "plt.tight_layout()\n",
                "plt.savefig(os.path.join(ANALYSIS_DIR, 'all_models_training_curves.png'), dpi=200)\n",
                "plt.show()\n",
                "\n",
                "print(f\"‚úÖ Saved: all_models_training_curves.png\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# METRICS BAR CHART\n",
                "# ============================================================\n",
                "\n",
                "fig, ax = plt.subplots(figsize=(12, 6))\n",
                "\n",
                "metric_names = ['accuracy', 'top5_accuracy', 'macro_f1']\n",
                "metric_labels = ['Accuracy', 'Top-5 Accuracy', 'Macro F1']\n",
                "x = np.arange(len(MODELS))\n",
                "width = 0.25\n",
                "\n",
                "for i, (metric, label) in enumerate(zip(metric_names, metric_labels)):\n",
                "    values = [metrics[m].get(metric, 0) for m in MODELS if m in metrics]\n",
                "    bars = ax.bar(x + i*width, values, width, label=label)\n",
                "    \n",
                "    for bar, val in zip(bars, values):\n",
                "        ax.annotate(f'{val:.3f}',\n",
                "                   xy=(bar.get_x() + bar.get_width()/2, bar.get_height()),\n",
                "                   xytext=(0, 3), textcoords='offset points',\n",
                "                   ha='center', fontsize=9)\n",
                "\n",
                "ax.set_xlabel('Model')\n",
                "ax.set_ylabel('Score')\n",
                "ax.set_title('Model Performance Comparison')\n",
                "ax.set_xticks(x + width)\n",
                "ax.set_xticklabels([m.replace('alexnet_', '').upper() for m in MODELS])\n",
                "ax.legend()\n",
                "ax.set_ylim(0, 1.1)\n",
                "ax.grid(alpha=0.3, axis='y')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig(os.path.join(ANALYSIS_DIR, 'all_models_metrics_comparison.png'), dpi=200)\n",
                "plt.show()\n",
                "\n",
                "print(f\"‚úÖ Saved: all_models_metrics_comparison.png\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# GENERATE REPORT DATA\n",
                "# ============================================================\n",
                "\n",
                "report_md = f\"\"\"# AlexNet iFood2019 - Team Results\n",
                "\n",
                "## Team Members & Models\n",
                "\n",
                "| Member | Model | Best Val Acc | Top-5 Acc | Macro F1 |\n",
                "|--------|-------|--------------|-----------|----------|\n",
                "\"\"\"\n",
                "\n",
                "for i, model in enumerate(MODELS):\n",
                "    if model in histories and model in metrics:\n",
                "        h = histories[model]\n",
                "        m = metrics[model]\n",
                "        report_md += f\"| {MEMBER_NAMES[i]} | {model.replace('alexnet_', '').upper()} | {max(h['val_acc']):.4f} | {m['top5_accuracy']:.4f} | {m['macro_f1']:.4f} |\\n\"\n",
                "\n",
                "# Best model\n",
                "best_model = max(metrics, key=lambda x: metrics[x]['accuracy'])\n",
                "best_acc = metrics[best_model]['accuracy']\n",
                "\n",
                "report_md += f\"\"\"\n",
                "## Best Model\n",
                "\n",
                "üèÜ **{best_model}** with accuracy: **{best_acc:.4f}**\n",
                "\n",
                "## Visualizations\n",
                "\n",
                "- Training Curves: `all_models_training_curves.png`\n",
                "- Metrics Comparison: `all_models_metrics_comparison.png`\n",
                "\"\"\"\n",
                "\n",
                "# Save\n",
                "with open(os.path.join(ANALYSIS_DIR, 'team_results_summary.md'), 'w') as f:\n",
                "    f.write(report_md)\n",
                "\n",
                "print(report_md)\n",
                "print(f\"\\n‚úÖ Saved: team_results_summary.md\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# SELESAI!\n",
                "# ============================================================\n",
                "\n",
                "print(\"\\n\" + \"=\" * 60)\n",
                "print(\"üéâ MERGE RESULTS COMPLETE!\")\n",
                "print(\"=\" * 60)\n",
                "print(f\"\\nSemua hasil tersimpan di: {ANALYSIS_DIR}\")\n",
                "print(\"\\nFile yang dihasilkan:\")\n",
                "print(\"  - team_results_comparison.csv\")\n",
                "print(\"  - team_results_summary.md\")\n",
                "print(\"  - all_models_training_curves.png\")\n",
                "print(\"  - all_models_metrics_comparison.png\")\n",
                "print(\"\\nGunakan file-file ini untuk mengisi FINAL_REPORT.md\")\n",
                "print(\"=\" * 60)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "accelerator": "GPU"
    },
    "nbformat": 4,
    "nbformat_minor": 4
}