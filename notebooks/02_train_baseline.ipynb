{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# AlexNet iFood2019 - Train Baseline Model\n",
                "\n",
                "This notebook trains a single AlexNet model (baseline by default).\n",
                "\n",
                "## Steps:\n",
                "1. Setup Environment\n",
                "2. Configure Training\n",
                "3. Train Model\n",
                "4. Evaluate Results\n",
                "5. Visualize Training Curves"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# Cell 1: Setup Environment\n",
                "# ============================================================\n",
                "\n",
                "from google.colab import drive\n",
                "drive.mount('/content/drive')\n",
                "\n",
                "import os\n",
                "import sys\n",
                "\n",
                "PROJECT_PATH = '/content/drive/MyDrive/AlexNet_iFood2019'\n",
                "REPO_PATH = '/content/alexnet-ifood2019'\n",
                "\n",
                "# Clone if needed\n",
                "if not os.path.exists(REPO_PATH):\n",
                "    !git clone https://github.com/deftorch/alexnet-ifood2019.git {REPO_PATH}\n",
                "\n",
                "os.chdir(REPO_PATH)\n",
                "sys.path.insert(0, REPO_PATH)\n",
                "\n",
                "# Create symlinks\n",
                "!rm -rf data checkpoints evaluation_results analysis_results\n",
                "!ln -s {PROJECT_PATH}/dataset data\n",
                "!ln -s {PROJECT_PATH}/checkpoints checkpoints\n",
                "!ln -s {PROJECT_PATH}/evaluation_results evaluation_results\n",
                "!ln -s {PROJECT_PATH}/analysis_results analysis_results\n",
                "\n",
                "print(\"‚úì Environment ready\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# Cell 2: Install Dependencies & Verify GPU\n",
                "# ============================================================\n",
                "\n",
                "!pip install -q torch torchvision pandas numpy pillow scikit-learn matplotlib seaborn tqdm wandb\n",
                "\n",
                "import torch\n",
                "print(f\"PyTorch: {torch.__version__}\")\n",
                "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
                "\n",
                "if torch.cuda.is_available():\n",
                "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
                "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
                "else:\n",
                "    print(\"‚ö†Ô∏è  No GPU! Go to Runtime > Change runtime type > GPU\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# Cell 3: Training Configuration\n",
                "# ============================================================\n",
                "\n",
                "# ‚öôÔ∏è MODIFY THESE SETTINGS AS NEEDED\n",
                "CONFIG = {\n",
                "    'model_name': 'alexnet_baseline',  # Options: alexnet_baseline, alexnet_mod1, alexnet_mod2, alexnet_combined\n",
                "    'num_epochs': 50,\n",
                "    'batch_size': 128,\n",
                "    'learning_rate': 0.01,\n",
                "    'momentum': 0.9,\n",
                "    'weight_decay': 0.0005,\n",
                "    'scheduler': 'step',  # Options: step, cosine\n",
                "    'num_workers': 4,\n",
                "    'use_wandb': False,  # Set True to log to Weights & Biases\n",
                "}\n",
                "\n",
                "print(\"Training Configuration:\")\n",
                "print(\"=\" * 40)\n",
                "for key, value in CONFIG.items():\n",
                "    print(f\"  {key}: {value}\")\n",
                "print(\"=\" * 40)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# Cell 4: Setup WandB (Optional)\n",
                "# ============================================================\n",
                "\n",
                "if CONFIG['use_wandb']:\n",
                "    import wandb\n",
                "    wandb.login()\n",
                "    print(\"‚úì WandB logged in\")\n",
                "else:\n",
                "    print(\"‚ÑπÔ∏è  WandB disabled - logging to console only\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# Cell 5: Start Training\n",
                "# ============================================================\n",
                "\n",
                "model_name = CONFIG['model_name']\n",
                "epochs = CONFIG['num_epochs']\n",
                "batch_size = CONFIG['batch_size']\n",
                "lr = CONFIG['learning_rate']\n",
                "momentum = CONFIG['momentum']\n",
                "wd = CONFIG['weight_decay']\n",
                "scheduler = CONFIG['scheduler']\n",
                "num_workers = CONFIG['num_workers']\n",
                "use_wandb = \"--use_wandb\" if CONFIG['use_wandb'] else \"\"\n",
                "\n",
                "!python src/train.py \\\n",
                "    --data_dir data \\\n",
                "    --model_name {model_name} \\\n",
                "    --num_epochs {epochs} \\\n",
                "    --batch_size {batch_size} \\\n",
                "    --lr {lr} \\\n",
                "    --momentum {momentum} \\\n",
                "    --weight_decay {wd} \\\n",
                "    --scheduler {scheduler} \\\n",
                "    --num_workers {num_workers} \\\n",
                "    --save_dir checkpoints \\\n",
                "    {use_wandb}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# Cell 6: Evaluate Model\n",
                "# ============================================================\n",
                "\n",
                "model_name = CONFIG['model_name']\n",
                "\n",
                "!python src/evaluate.py \\\n",
                "    --data_dir data \\\n",
                "    --model_path checkpoints/{model_name}_best.pth \\\n",
                "    --model_name {model_name} \\\n",
                "    --split val \\\n",
                "    --output_dir evaluation_results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# Cell 7: Visualize Training Curves\n",
                "# ============================================================\n",
                "\n",
                "import json\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "model_name = CONFIG['model_name']\n",
                "history_file = f'checkpoints/{model_name}_history.json'\n",
                "\n",
                "if os.path.exists(history_file):\n",
                "    with open(history_file) as f:\n",
                "        history = json.load(f)\n",
                "    \n",
                "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
                "    epochs = range(1, len(history['train_loss']) + 1)\n",
                "    \n",
                "    # Loss\n",
                "    axes[0].plot(epochs, history['train_loss'], label='Train', linewidth=2)\n",
                "    axes[0].plot(epochs, history['val_loss'], label='Validation', linewidth=2)\n",
                "    axes[0].set_xlabel('Epoch')\n",
                "    axes[0].set_ylabel('Loss')\n",
                "    axes[0].set_title('Training & Validation Loss')\n",
                "    axes[0].legend()\n",
                "    axes[0].grid(alpha=0.3)\n",
                "    \n",
                "    # Accuracy\n",
                "    axes[1].plot(epochs, history['train_acc'], label='Train', linewidth=2)\n",
                "    axes[1].plot(epochs, history['val_acc'], label='Validation', linewidth=2)\n",
                "    axes[1].set_xlabel('Epoch')\n",
                "    axes[1].set_ylabel('Accuracy')\n",
                "    axes[1].set_title('Training & Validation Accuracy')\n",
                "    axes[1].legend()\n",
                "    axes[1].grid(alpha=0.3)\n",
                "    \n",
                "    plt.suptitle(f'{model_name} Training Curves', fontsize=14)\n",
                "    plt.tight_layout()\n",
                "    plt.savefig(f'analysis_results/{model_name}_training_curves.png', dpi=150)\n",
                "    plt.show()\n",
                "    \n",
                "    # Summary\n",
                "    print(\"\\nTraining Summary:\")\n",
                "    print(f\"  Final Train Loss: {history['train_loss'][-1]:.4f}\")\n",
                "    print(f\"  Final Train Acc: {history['train_acc'][-1]:.4f}\")\n",
                "    print(f\"  Best Val Acc: {max(history['val_acc']):.4f}\")\n",
                "    print(f\"  Best Val Epoch: {history['val_acc'].index(max(history['val_acc'])) + 1}\")\n",
                "else:\n",
                "    print(f\"‚ö†Ô∏è  History file not found: {history_file}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# Cell 8: Keep Session Alive (for long training)\n",
                "# ============================================================\n",
                "\n",
                "from IPython.display import Javascript\n",
                "\n",
                "display(Javascript('''\n",
                "    function ClickConnect(){\n",
                "        console.log(\"Keeping session alive...\");\n",
                "        document.querySelector(\"colab-connect-button\").click()\n",
                "    }\n",
                "    setInterval(ClickConnect, 60000)\n",
                "'''))\n",
                "\n",
                "print(\"‚úì Keep-alive script running\")\n",
                "print(\"üí° This prevents Colab from disconnecting during long training\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "accelerator": "GPU"
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
